{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca15352",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-20T05:32:39.374618Z",
     "iopub.status.busy": "2025-05-20T05:32:39.374371Z",
     "iopub.status.idle": "2025-05-20T05:32:47.117325Z",
     "shell.execute_reply": "2025-05-20T05:32:47.116585Z"
    },
    "papermill": {
     "duration": 7.749428,
     "end_time": "2025-05-20T05:32:47.119294",
     "exception": false,
     "start_time": "2025-05-20T05:32:39.369866",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\r\n",
      "Collecting pip\r\n",
      "  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Downloading pip-25.1.1-py3-none-any.whl (1.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pip\r\n",
      "  Attempting uninstall: pip\r\n",
      "    Found existing installation: pip 24.1.2\r\n",
      "    Uninstalling pip-24.1.2:\r\n",
      "      Successfully uninstalled pip-24.1.2\r\n",
      "Successfully installed pip-25.1.1\r\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\r\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.0rc1)\r\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\r\n",
      "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\r\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\r\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\r\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\r\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\r\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\r\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\r\n",
      "Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\r\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\r\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\r\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\r\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\r\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.3.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install tensorflow wandb numpy pandas tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00c88955",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:32:47.128719Z",
     "iopub.status.busy": "2025-05-20T05:32:47.128492Z",
     "iopub.status.idle": "2025-05-20T05:32:50.518451Z",
     "shell.execute_reply": "2025-05-20T05:32:50.517833Z"
    },
    "papermill": {
     "duration": 3.395842,
     "end_time": "2025-05-20T05:32:50.519598",
     "exception": false,
     "start_time": "2025-05-20T05:32:47.123756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24s006\u001b[0m (\u001b[33mda24s006-indian-institue-of-technology-madras-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key='613aac3388325cb6206db61e3c1a38a707589743')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ab549",
   "metadata": {
    "papermill": {
     "duration": 0.003834,
     "end_time": "2025-05-20T05:32:50.527696",
     "exception": false,
     "start_time": "2025-05-20T05:32:50.523862",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Preparation:\n",
    "- downloading and extracting dikshina hindi lexicon: already downloaded and uploaded the relavant part of the data in the kaggle environment.\n",
    "- building character vocabularies and dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f57df31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:32:50.537016Z",
     "iopub.status.busy": "2025-05-20T05:32:50.536753Z",
     "iopub.status.idle": "2025-05-20T05:32:56.434888Z",
     "shell.execute_reply": "2025-05-20T05:32:56.434295Z"
    },
    "papermill": {
     "duration": 5.904254,
     "end_time": "2025-05-20T05:32:56.436169",
     "exception": false,
     "start_time": "2025-05-20T05:32:50.531915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_utils.py\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def build_vocab(pairs, specials=['<pad>','<sos>','<eos>']):\n",
    "    chars = set(''.join(pairs))\n",
    "    idx = {tok:i for i,tok in enumerate(specials)}\n",
    "    for c in sorted(chars):\n",
    "        idx[c] = len(idx)\n",
    "    return idx\n",
    "\n",
    "class TransliterationDataset(Dataset):\n",
    "    def __init__(self, path, src_vocab, tgt_vocab, max_len=32):\n",
    "        df = pd.read_csv(path, sep='\\t', names=['devanagari','roman','dont_care'])\n",
    "        df = df.dropna()\n",
    "        self.pairs = df[['roman','devanagari']].values.tolist()\n",
    "        self.src_vocab, self.tgt_vocab = src_vocab, tgt_vocab\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        src, tgt = self.pairs[i]\n",
    "        # src: [c1,c2,...] -> [..., <eos>]\n",
    "        src_ids = [self.src_vocab[c] for c in src][:self.max_len] + [self.src_vocab['<eos>']]\n",
    "        # tgt: [<sos>, c1,c2,..., <eos>]\n",
    "        tgt_ids = [self.tgt_vocab['<sos>']] + \\\n",
    "                  [self.tgt_vocab[c] for c in tgt][:self.max_len] + \\\n",
    "                  [self.tgt_vocab['<eos>']]\n",
    "        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    srcs, tgts = zip(*batch)\n",
    "    srcs_p = pad_sequence(srcs, batch_first=True, padding_value=src_vocab['<pad>'])\n",
    "    tgts_p = pad_sequence(tgts, batch_first=True, padding_value=tgt_vocab['<pad>'])\n",
    "    return srcs_p, tgts_p\n",
    "\n",
    "# Build vocabs once\n",
    "df = pd.read_csv('/kaggle/input/lexicons-hindi-transliteration/hi.translit.sampled.train.tsv', sep='\\t', names=['devanagari','roman','dont_care'])\n",
    "df = df.dropna()\n",
    "src_vocab = build_vocab(df['roman'])\n",
    "tgt_vocab = build_vocab(df['devanagari'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5f56ac",
   "metadata": {
    "papermill": {
     "duration": 0.003866,
     "end_time": "2025-05-20T05:32:56.444195",
     "exception": false,
     "start_time": "2025-05-20T05:32:56.440329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model Definition\n",
    "- Encoder and Decoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9bf1df8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:32:56.453256Z",
     "iopub.status.busy": "2025-05-20T05:32:56.453049Z",
     "iopub.status.idle": "2025-05-20T05:32:56.468323Z",
     "shell.execute_reply": "2025-05-20T05:32:56.467583Z"
    },
    "papermill": {
     "duration": 0.021312,
     "end_time": "2025-05-20T05:32:56.469382",
     "exception": false,
     "start_time": "2025-05-20T05:32:56.448070",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.py\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, inp_dim, emb_dim, hid_dim, n_layers, cell, dropout):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(inp_dim, emb_dim)\n",
    "        RNN = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell]\n",
    "        self.rnn = RNN(emb_dim, hid_dim, n_layers,\n",
    "                       dropout=dropout if n_layers>1 else 0,\n",
    "                       batch_first=True)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: [B, S]\n",
    "        e = self.drop(self.emb(x))\n",
    "        out, hidden = self.rnn(e)\n",
    "        return out, hidden\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \n",
    "    def __init__(self, hid_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Linear(hid_dim*2, hid_dim)\n",
    "        self.v    = nn.Linear(hid_dim, 1, bias=False)\n",
    "        \n",
    "    def forward(self, hidden, enc_out):\n",
    "        # hidden: [B, H], enc_out: [B, S, H]\n",
    "        B, S, H = enc_out.size()\n",
    "        h = hidden.unsqueeze(1).repeat(1,S,1)               # [B,S,H]\n",
    "        energy = torch.tanh(self.attn(torch.cat([h,enc_out],dim=2)))  # [B,S,H]\n",
    "        scores = self.v(energy).squeeze(2)                  # [B,S]\n",
    "        return F.softmax(scores, dim=1)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, out_dim, emb_dim, hid_dim, n_layers, cell, dropout, use_attn=False):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(out_dim, emb_dim)\n",
    "        RNN = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell]\n",
    "        self.rnn = RNN(emb_dim + (hid_dim if use_attn else 0),\n",
    "                       hid_dim, n_layers,\n",
    "                       dropout=dropout if n_layers>1 else 0,\n",
    "                       batch_first=True)\n",
    "        self.fc  = nn.Linear(hid_dim, out_dim)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.use_attn = use_attn\n",
    "        if use_attn: self.attn = Attention(hid_dim)\n",
    "\n",
    "    def forward(self, tgt_tok, hidden, enc_out=None):\n",
    "        # tgt_tok: [B], hidden: (h_n, c_n)? or h_n\n",
    "        B = tgt_tok.size(0)\n",
    "        t = tgt_tok.unsqueeze(1)            # [B,1]\n",
    "        emb = self.drop(self.emb(t))        # [B,1,E]\n",
    "        \n",
    "        if self.use_attn:\n",
    "            h = hidden[-1] if not isinstance(hidden, tuple) else hidden[0][-1]\n",
    "            attn_w = self.attn(h, enc_out)  # [B, S]\n",
    "            ctx    = torch.bmm(attn_w.unsqueeze(1), enc_out)  # [B,1,H]\n",
    "            rnn_in = torch.cat([emb, ctx], dim=2)\n",
    "        else:\n",
    "            rnn_in = emb\n",
    "        out, hidden = self.rnn(rnn_in, hidden)\n",
    "        pred = self.fc(out.squeeze(1))      # [B, out_dim]\n",
    "        \n",
    "        return pred, hidden, (attn_w if self.use_attn else None)\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, enc, dec, pad_idx, device):\n",
    "        super().__init__()\n",
    "        self.enc, self.dec = enc, dec\n",
    "        self.pad_idx = pad_idx\n",
    "        self.device  = device\n",
    "\n",
    "    # def _init_decoder_hidden(self, enc_hidden):\n",
    "    #     # Handles both GRU (Tensor) and LSTM (tuple) encoder hidden states\n",
    "    #     if isinstance(enc_hidden, tuple):  # LSTM: (h_n, c_n)\n",
    "    #         h, c = enc_hidden\n",
    "    #         dec_layers = self.dec.rnn.num_layers\n",
    "    #         B, H = h.size(1), h.size(2)\n",
    "    #         # Prepare zero-padded states\n",
    "    #         h0 = torch.zeros(dec_layers, B, H, device=self.device)\n",
    "    #         c0 = torch.zeros(dec_layers, B, H, device=self.device)\n",
    "    #         # Copy encoder layers into decoder state\n",
    "    #         h0[:h.size(0)] = h\n",
    "    #         c0[:c.size(0)] = c\n",
    "    #         return (h0, c0)\n",
    "    #     else:  # GRU or RNN\n",
    "    #         h = enc_hidden\n",
    "    #         dec_layers = self.dec.rnn.num_layers\n",
    "    #         B, H = h.size(1), h.size(2)\n",
    "    #         h0 = torch.zeros(dec_layers, B, H, device=self.device)\n",
    "    #         h0[:h.size(0)] = h\n",
    "    #         return h0\n",
    "\n",
    "    def _init_decoder_hidden(self, enc_hidden):\n",
    "       \n",
    "        dec_layers = self.dec.rnn.num_layers\n",
    "    \n",
    "        if isinstance(enc_hidden, tuple):  # LSTM: (h, c)\n",
    "            h, c = enc_hidden\n",
    "            enc_layers, B, H = h.size()\n",
    "            # Prepare zero states\n",
    "            h0 = torch.zeros(dec_layers,  B, H, device=self.device)\n",
    "            c0 = torch.zeros(dec_layers,  B, H, device=self.device)\n",
    "            # Number of layers to copy\n",
    "            n = min(enc_layers, dec_layers)\n",
    "            # Copy last n layers from encoder into bottom of decoder state\n",
    "            h0[-n:] = h[-n:]\n",
    "            c0[-n:] = c[-n:]\n",
    "            return (h0, c0)\n",
    "\n",
    "        else:  # GRU or vanilla RNN\n",
    "            h = enc_hidden\n",
    "            enc_layers, B, H = h.size()\n",
    "            h0 = torch.zeros(dec_layers, B, H, device=self.device)\n",
    "            n = min(enc_layers, dec_layers)\n",
    "            h0[-n:] = h[-n:]\n",
    "            return h0\n",
    "\n",
    "\n",
    "    def forward(self, src, tgt, teacher_forcing=0.5):\n",
    "        B, T = tgt.size()\n",
    "        out_dim = self.dec.fc.out_features\n",
    "        outputs = torch.zeros(B, T, out_dim, device=self.device)\n",
    "\n",
    "        enc_out, enc_hidden = self.enc(src)\n",
    "        # Initialize decoder hidden state to match dec_layers\n",
    "        dec_hidden = self._init_decoder_hidden(enc_hidden)\n",
    "\n",
    "        inp = tgt[:,0]  # <sos>\n",
    "        for t in range(1, T):\n",
    "            pred, dec_hidden, _ = self.dec(\n",
    "                inp, dec_hidden,\n",
    "                enc_out if self.dec.use_attn else None\n",
    "            )\n",
    "            outputs[:,t] = pred\n",
    "            top1 = pred.argmax(1)\n",
    "            inp = tgt[:,t] if torch.rand(1).item() < teacher_forcing else top1\n",
    "\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626473ba",
   "metadata": {
    "papermill": {
     "duration": 0.003817,
     "end_time": "2025-05-20T05:32:56.477277",
     "exception": false,
     "start_time": "2025-05-20T05:32:56.473460",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Beam Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f06d029",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:32:56.486293Z",
     "iopub.status.busy": "2025-05-20T05:32:56.486066Z",
     "iopub.status.idle": "2025-05-20T05:32:56.494553Z",
     "shell.execute_reply": "2025-05-20T05:32:56.493851Z"
    },
    "papermill": {
     "duration": 0.01424,
     "end_time": "2025-05-20T05:32:56.495629",
     "exception": false,
     "start_time": "2025-05-20T05:32:56.481389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# beam_search.py\n",
    "import torch, torch.nn.functional as F\n",
    "from queue import PriorityQueue\n",
    "from math import log\n",
    "\n",
    "class BeamNode:\n",
    "    def __init__(self, hidden, prev, tok, logp, length):\n",
    "        self.hidden, self.prev, self.tok = hidden, prev, tok\n",
    "        self.logp, self.len = logp, length\n",
    "    def score(self): return self.logp / float(self.len)\n",
    "\n",
    "def beam_decode(model, src, src_vocab, tgt_vocab, beam_k=3, max_len=32, device='cpu'):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        enc_out, hidden = model.enc(src)\n",
    "        # init beam\n",
    "        init_tok = torch.tensor([tgt_vocab['<sos>']], device=device)\n",
    "        node = BeamNode(hidden, None, init_tok, 0.0, 1)\n",
    "        pq = PriorityQueue(); pq.put((-node.score(), node))\n",
    "        end_beams = []\n",
    "        while not pq.empty():\n",
    "            _, n = pq.get()\n",
    "            if n.tok.item()==tgt_vocab['<eos>'] and n.prev is not None:\n",
    "                end_beams.append((n.score(), n))\n",
    "                if len(end_beams)>=beam_k: break\n",
    "            inp = n.tok\n",
    "            pred, hid, _ = model.dec(inp, n.hidden, enc_out if model.dec.use_attn else None)\n",
    "            logps = F.log_softmax(pred, dim=1)\n",
    "            topv, topi = logps.topk(beam_k)\n",
    "            for i in range(beam_k):\n",
    "                tok_i = topi[0][i].unsqueeze(0)\n",
    "                score = n.logp + topv[0][i].item()\n",
    "                new_node = BeamNode(hid, n, tok_i, score, n.len+1)\n",
    "                pq.put((-new_node.score(), new_node))\n",
    "        # backtrack best\n",
    "        best = sorted(end_beams, key=lambda x: x[0], reverse=True)[0][1]\n",
    "        seq = []\n",
    "        while best.prev is not None:\n",
    "            seq.append(best.tok.item()); best = best.prev\n",
    "        return seq[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad158c",
   "metadata": {
    "papermill": {
     "duration": 0.003587,
     "end_time": "2025-05-20T05:32:56.502965",
     "exception": false,
     "start_time": "2025-05-20T05:32:56.499378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Training, Evaluation & W&B Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcc9c873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:32:56.511587Z",
     "iopub.status.busy": "2025-05-20T05:32:56.511369Z",
     "iopub.status.idle": "2025-05-20T05:32:56.601763Z",
     "shell.execute_reply": "2025-05-20T05:32:56.601037Z"
    },
    "papermill": {
     "duration": 0.096044,
     "end_time": "2025-05-20T05:32:56.602859",
     "exception": false,
     "start_time": "2025-05-20T05:32:56.506815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train.py\n",
    "import wandb, torch, torch.optim as optim, torch.nn as nn\n",
    "# from data_utils import TransliterationDataset, collate_fn, src_vocab, tgt_vocab\n",
    "# from model import Encoder, Decoder, Seq2Seq\n",
    "# from beam_search import beam_decode\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "pad_idx = tgt_vocab['<pad>']\n",
    "\n",
    "sweep_config = {\n",
    "  'method': 'bayes',\n",
    "  'metric': {'name':'val_loss','goal':'minimize'},\n",
    "  'parameters':{\n",
    "    'emb_dim':   {'values':[16,32,64,256]},\n",
    "    'hid_dim':   {'values':[16,32,64,256]},\n",
    "    'enc_layers':{'values':[1,2,3]},\n",
    "    'dec_layers':{'values':[1,2,3]},\n",
    "    'cell_type': {'values':['RNN','GRU','LSTM']},\n",
    "    'dropout':   {'values':[0.2,0.3]},\n",
    "    'beam_size': {'values':[1,3,5]},\n",
    "    'lr':        {'value':1e-3},\n",
    "    'batch_size':{'value':128}\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cd8f3be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:32:56.612081Z",
     "iopub.status.busy": "2025-05-20T05:32:56.611689Z",
     "iopub.status.idle": "2025-05-20T05:32:56.619810Z",
     "shell.execute_reply": "2025-05-20T05:32:56.619095Z"
    },
    "papermill": {
     "duration": 0.01405,
     "end_time": "2025-05-20T05:32:56.620967",
     "exception": false,
     "start_time": "2025-05-20T05:32:56.606917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def train_epoch(model, loader, opt, crit):\n",
    "#     model.train(); total=0\n",
    "#     for src, tgt in loader:\n",
    "#         src, tgt = src.to(device), tgt.to(device)\n",
    "#         opt.zero_grad()\n",
    "#         out = model(src, tgt,teacher_forcing=0.5)\n",
    "#         loss = crit(out[:,1:].reshape(-1,out.size(-1)), tgt[:,1:].reshape(-1))\n",
    "#         loss.backward()\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(),1)\n",
    "#         opt.step(); total += loss.item()\n",
    "#     return total/len(loader)\n",
    "\n",
    "# def eval_epoch(model, loader, crit, beam_k):\n",
    "#     model.eval(); total=0\n",
    "#     with torch.no_grad():\n",
    "#         for src,tgt in loader:\n",
    "#             src,tgt = src.to(device), tgt.to(device)\n",
    "#             # teacher_forced loss\n",
    "#             out = model(src,tgt,teacher_forcing=0.0)\n",
    "#             total += crit(out[:,1:].reshape(-1,out.size(-1)), tgt[:,1:].reshape(-1)).item()\n",
    "#     return total/len(loader)\n",
    "\n",
    "def calculate_accuracy(output, target, pad_idx):\n",
    "    # output: [B, T, V], target: [B, T]\n",
    "    with torch.no_grad():\n",
    "        pred_tokens = output.argmax(dim=2)           # [B, T]\n",
    "        mask        = target != pad_idx              # ignore pads\n",
    "        correct     = (pred_tokens == target) & mask\n",
    "        return correct.sum().float() / mask.sum().float()\n",
    "\n",
    "def train_epoch(model, loader, opt, crit, pad_idx):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc  = 0\n",
    "    for src, tgt in loader:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        opt.zero_grad()\n",
    "        out  = model(src, tgt, teacher_forcing=0.5)\n",
    "        loss = crit(out[:,1:].reshape(-1,out.size(-1)), tgt[:,1:].reshape(-1))\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
    "        opt.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_acc  += calculate_accuracy(out[:,1:], tgt[:,1:], pad_idx)\n",
    "    return total_loss/len(loader), total_acc/len(loader)\n",
    "\n",
    "def eval_epoch(model, loader, crit, beam_k, pad_idx):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc  = 0\n",
    "    with torch.no_grad():\n",
    "        for src, tgt in loader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            out  = model(src, tgt, teacher_forcing=0.0)\n",
    "            loss = crit(out[:,1:].reshape(-1,out.size(-1)), tgt[:,1:].reshape(-1))\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_acc  += calculate_accuracy(out[:,1:], tgt[:,1:], pad_idx)\n",
    "    return total_loss/len(loader), total_acc/len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7ec5296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T05:32:56.629515Z",
     "iopub.status.busy": "2025-05-20T05:32:56.629109Z",
     "iopub.status.idle": "2025-05-20T07:07:10.671856Z",
     "shell.execute_reply": "2025-05-20T07:07:10.671205Z"
    },
    "papermill": {
     "duration": 5654.091207,
     "end_time": "2025-05-20T07:07:10.715957",
     "exception": false,
     "start_time": "2025-05-20T05:32:56.624750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: twa746j3\n",
      "Sweep URL: https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 33fyuoza with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_053257-33fyuoza\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mswept-sweep-1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/33fyuoza\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading history steps 8-9, summary\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▂▄▅▆▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▆▅▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▃▄▅▆▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ██▆▅▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.61955\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 1.27923\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.57635\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.46702\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mswept-sweep-1\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/33fyuoza\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_053257-33fyuoza/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sg38vmgh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_053434-sg38vmgh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvague-sweep-2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/sg38vmgh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▄▅▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▅▄▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▅▄▂▄▁▃▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▆▆█▅▇▆▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.25604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.80206\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.21107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 3.02414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvague-sweep-2\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/sg38vmgh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_053434-sg38vmgh/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yn9twlhh with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_053550-yn9twlhh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfaithful-sweep-3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/yn9twlhh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▅▆▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▃▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc █████▃▂▁▂▃\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▄▃▃▃▁▅▇█▇▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.22412\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.95547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.16742\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 3.22102\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfaithful-sweep-3\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/yn9twlhh\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_053550-yn9twlhh/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qqcfavr1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_053727-qqcfavr1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mspring-sweep-4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/qqcfavr1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▅▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.79596\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.66991\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.67773\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.12404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mspring-sweep-4\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/qqcfavr1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_053727-qqcfavr1/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1wicwu7r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_053909-1wicwu7r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtough-sweep-5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/1wicwu7r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▄▅▅▅▆▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▅▄▄▃▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▁▁▂▃▃▄▅▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▇▆▅▅▄▃▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.31223\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.53507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.2925\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 2.63683\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtough-sweep-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/1wicwu7r\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_053909-1wicwu7r/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sf0okach with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_054100-sf0okach\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtwilight-sweep-6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/sf0okach\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▄▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▅▅▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▂▃▄▅▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▆▅▄▄▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.34391\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.3733\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.33328\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 2.43088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtwilight-sweep-6\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/sf0okach\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_054100-sf0okach/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w2tzby2x with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_054303-w2tzby2x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcrimson-sweep-7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/w2tzby2x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▆▇▇█▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▃▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ██████▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▄▃▃▂▁▄▆▇▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.21709\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.98282\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.19315\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 3.18376\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcrimson-sweep-7\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/w2tzby2x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_054303-w2tzby2x/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: oeiz9rv7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_054429-oeiz9rv7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdevoted-sweep-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/oeiz9rv7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▃▄▅▅▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▆▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▁▂▃▄▅▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ██▇▆▅▄▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.38018\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.21126\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.37197\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 2.27499\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdevoted-sweep-8\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/oeiz9rv7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_054429-oeiz9rv7/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ue3i24zp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_054615-ue3i24zp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfirm-sweep-9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ue3i24zp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▃▃▃▄▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▆▆▅▄▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▃▄▄▁▄▄▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▆▅▅█▅▄▃▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.27863\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.63983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.2411\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 2.92453\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfirm-sweep-9\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ue3i24zp\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_054615-ue3i24zp/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ofxkpq2q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_054737-ofxkpq2q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgood-sweep-10\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ofxkpq2q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading history steps 9-9, summary\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▄▄▆▆▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▅▄▃▂▂▂▂▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▅▁▅▇▇▇▇▇█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▆█▇▃▂▃▃▂▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.26204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.72933\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.19181\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 3.11282\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgood-sweep-10\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ofxkpq2q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_054737-ofxkpq2q/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w43s6qxb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_054923-w43s6qxb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33miconic-sweep-11\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/w43s6qxb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▄▅▆▆▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▂▁▄▄▅▆▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▅▅▄▃▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.29416\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.59846\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.26408\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 2.75404\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33miconic-sweep-11\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/w43s6qxb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_054923-w43s6qxb/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1q21rqmv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_055105-1q21rqmv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvibrant-sweep-12\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/1q21rqmv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▃▄▅▅▆▇▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▅▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▃▄▅▆▆▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▆▅▄▃▃▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.39734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.14255\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.38761\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 2.18713\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvibrant-sweep-12\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/1q21rqmv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_055105-1q21rqmv/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2bu8noda with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_055246-2bu8noda\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33methereal-sweep-13\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/2bu8noda\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▄▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▄▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▄▆▃▁▄▂▇▇█▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss ▃▃▆█▆▆▃▅▁▅\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.25098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 2.79426\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.1577\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 3.31097\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33methereal-sweep-13\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/2bu8noda\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_055246-2bu8noda/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cpgop5ho with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_055408-cpgop5ho\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmisunderstood-sweep-14\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/cpgop5ho\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▃▅▆▆▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▆▄▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▄▅▆▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▅▄▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.62498\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 1.24334\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.5853\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.38547\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmisunderstood-sweep-14\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/cpgop5ho\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_055408-cpgop5ho/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7zfm9oab with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_055554-7zfm9oab\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtrim-sweep-15\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/7zfm9oab\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▃▄▅▆▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▅▄▃▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▃▄▅▆▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▆▅▄▃▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.55137\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 1.49551\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.51764\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.64779\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtrim-sweep-15\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/7zfm9oab\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_055554-7zfm9oab/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kflmbjcb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_055720-kflmbjcb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbumbling-sweep-16\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/kflmbjcb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▄▆▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▅▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▅▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▄▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.83515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.54099\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.70851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.05656\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbumbling-sweep-16\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/kflmbjcb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_055720-kflmbjcb/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vph73967 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_055907-vph73967\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmild-sweep-17\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/vph73967\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▅▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.81254\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.61512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.70818\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.03159\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmild-sweep-17\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/vph73967\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_055907-vph73967/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3e5wgx9g with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_060104-3e5wgx9g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mnoble-sweep-18\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/3e5wgx9g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▄▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▅▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▅▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▃▂▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.86111\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.46245\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71718\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.01401\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mnoble-sweep-18\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/3e5wgx9g\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_060104-3e5wgx9g/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ofbizjjs with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_060301-ofbizjjs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvivid-sweep-19\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ofbizjjs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.83857\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.53549\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.72112\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.0221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvivid-sweep-19\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ofbizjjs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_060301-ofbizjjs/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n7fgjbm8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_060503-n7fgjbm8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdeep-sweep-20\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/n7fgjbm8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▅▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▅▆▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▄▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.82625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.57449\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.69124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.0866\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdeep-sweep-20\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/n7fgjbm8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_060503-n7fgjbm8/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ipful5ap with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_060655-ipful5ap\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mjumping-sweep-21\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ipful5ap\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▅▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▅▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▄▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.84165\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.52466\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71566\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.00701\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mjumping-sweep-21\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ipful5ap\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_060655-ipful5ap/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5ja0r9t6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_060851-5ja0r9t6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mstill-sweep-22\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/5ja0r9t6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▅▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.75881\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.79027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.66764\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.15064\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mstill-sweep-22\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/5ja0r9t6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_060851-5ja0r9t6/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: a6bmv9th with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_061043-a6bmv9th\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msparkling-sweep-23\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/a6bmv9th\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▅▆▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▄▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.83695\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.53727\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.03388\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msparkling-sweep-23\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/a6bmv9th\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_061043-a6bmv9th/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3irk4an3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_061300-3irk4an3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mupbeat-sweep-24\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/3irk4an3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▄▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.80905\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.62851\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.69569\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.09546\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mupbeat-sweep-24\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/3irk4an3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_061300-3irk4an3/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 82754fav with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_061452-82754fav\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdark-sweep-25\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/82754fav\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▅▆▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▄▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.8346\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.54377\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71738\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.02865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdark-sweep-25\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/82754fav\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_061452-82754fav/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: g24622eo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_061649-g24622eo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mzany-sweep-26\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/g24622eo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▃▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▄▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.80188\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.64807\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.69538\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.05039\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mzany-sweep-26\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/g24622eo\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_061649-g24622eo/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n1epezm2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_061826-n1epezm2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mtwilight-sweep-27\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/n1epezm2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▂▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.83263\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.55211\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.02098\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mtwilight-sweep-27\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/n1epezm2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_061826-n1epezm2/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kyxphpzu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_062028-kyxphpzu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mclean-sweep-28\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/kyxphpzu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▅▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.80083\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.65267\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.69831\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.05342\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mclean-sweep-28\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/kyxphpzu\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_062028-kyxphpzu/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8jhwc6z9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_062209-8jhwc6z9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrobust-sweep-29\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/8jhwc6z9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.83003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.55984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71277\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.04324\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrobust-sweep-29\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/8jhwc6z9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_062209-8jhwc6z9/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ft83j0cz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_062426-ft83j0cz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33msmooth-sweep-30\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ft83j0cz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▄▅▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.77267\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.75115\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.68393\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.10135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33msmooth-sweep-30\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ft83j0cz\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_062426-ft83j0cz/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yrqd1gw5 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_062619-yrqd1gw5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflowing-sweep-31\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/yrqd1gw5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.7893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.69088\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.68515\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.08607\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflowing-sweep-31\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/yrqd1gw5\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_062619-yrqd1gw5/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dx04v7lx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_062810-dx04v7lx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mlemon-sweep-32\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/dx04v7lx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▅▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.77396\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.73711\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.67896\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.11108\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mlemon-sweep-32\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/dx04v7lx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_062810-dx04v7lx/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 33941cw9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_062947-33941cw9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mflowing-sweep-33\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/33941cw9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▃▄▆▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▆▄▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▂▄▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▇▅▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.7716\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.75462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.69672\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.05756\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mflowing-sweep-33\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/33941cw9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_062947-33941cw9/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: apx43kdf with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_063214-apx43kdf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mhardy-sweep-34\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/apx43kdf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▅▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▅▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.77865\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.72003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.69394\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.05441\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mhardy-sweep-34\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/apx43kdf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_063214-apx43kdf/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: xns03ve9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_063412-xns03ve9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfresh-sweep-35\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/xns03ve9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▅▆▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▅▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.76097\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.78588\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.67522\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.14793\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfresh-sweep-35\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/xns03ve9\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_063412-xns03ve9/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zkthauh6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_063612-zkthauh6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcomfy-sweep-36\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/zkthauh6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.7903\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.68567\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.69261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.07151\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcomfy-sweep-36\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/zkthauh6\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_063612-zkthauh6/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zz6i8qyv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_063755-zz6i8qyv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mworldly-sweep-37\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/zz6i8qyv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.77406\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.73614\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.68562\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.06988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mworldly-sweep-37\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/zz6i8qyv\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_063755-zz6i8qyv/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: rbnk6d42 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_063937-rbnk6d42\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgolden-sweep-38\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/rbnk6d42\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.84266\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.52219\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.72439\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.01977\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mgolden-sweep-38\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/rbnk6d42\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_063937-rbnk6d42/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ug77tmuq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_064159-ug77tmuq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdecent-sweep-39\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ug77tmuq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▅▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.78364\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.71121\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.68168\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.12131\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdecent-sweep-39\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ug77tmuq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_064159-ug77tmuq/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: m51m2snx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_064352-m51m2snx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrich-sweep-40\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/m51m2snx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▅▆▇▇▇██\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▃▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.74027\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.84759\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.66357\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.14893\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrich-sweep-40\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/m51m2snx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_064352-m51m2snx/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qxvjvwkl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_064527-qxvjvwkl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33methereal-sweep-41\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/qxvjvwkl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▅▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▅▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▄▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.81495\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.61314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71253\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.02107\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33methereal-sweep-41\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/qxvjvwkl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_064527-qxvjvwkl/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 09gce74q with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_064754-09gce74q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbright-sweep-42\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/09gce74q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.81691\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.60474\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.70984\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.03604\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbright-sweep-42\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/09gce74q\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_064754-09gce74q/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w1mtsum3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_065012-w1mtsum3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfirm-sweep-43\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/w1mtsum3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.82045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.59035\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71753\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.02717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfirm-sweep-43\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/w1mtsum3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_065012-w1mtsum3/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zdg1jr86 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_065234-zdg1jr86\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mbumbling-sweep-44\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/zdg1jr86\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▅▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▆▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.81983\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.59372\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71124\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.00765\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mbumbling-sweep-44\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/zdg1jr86\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_065234-zdg1jr86/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: anvgqdav with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_065456-anvgqdav\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mcomfy-sweep-45\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/anvgqdav\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▄▆▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▅▃▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▅▆▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▃▂▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.86135\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.46351\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.72056\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.00414\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mcomfy-sweep-45\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/anvgqdav\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_065456-anvgqdav/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sg1eyow3 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_065653-sg1eyow3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mvivid-sweep-46\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/sg1eyow3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▃▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▄▃▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.80934\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.62468\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.70184\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.06451\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mvivid-sweep-46\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/sg1eyow3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_065653-sg1eyow3/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j32plw6b with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_065829-j32plw6b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrobust-sweep-47\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/j32plw6b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▄▃▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.82494\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.57734\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71717\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.01988\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mrobust-sweep-47\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/j32plw6b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_065829-j32plw6b/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vfv4moet with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_070056-vfv4moet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mfast-sweep-48\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/vfv4moet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.80314\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.65044\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71019\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.04062\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mfast-sweep-48\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/vfv4moet\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_070056-vfv4moet/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ufje5cyj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_070313-ufje5cyj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdandy-sweep-49\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ufje5cyj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: uploading model_without_attn.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▂▄▆▆▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▇▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▃▅▆▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.82307\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.59042\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.71261\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.04217\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mdandy-sweep-49\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/ufje5cyj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_070313-ufje5cyj/logs\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l85z3c7c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.9\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20250520_070531-l85z3c7c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mquiet-sweep-50\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🧹 View sweep at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/twa746j3\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/l85z3c7c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch ▁▂▃▃▄▅▆▆▇█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc ▁▃▅▆▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss █▆▄▃▂▂▂▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc ▁▄▆▇▇▇████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss █▅▃▂▂▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      epoch 10\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  train_acc 0.80057\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train_loss 0.65417\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    val_acc 0.69094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val_loss 1.07475\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mquiet-sweep-50\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/l85z3c7c\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at: \u001b[34m\u001b[4mhttps://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20250520_070531-l85z3c7c/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def sweep_run():\n",
    "    wandb.init()\n",
    "    cfg = wandb.config\n",
    "    \n",
    "    # data\n",
    "    ds = TransliterationDataset('/kaggle/input/lexicons-hindi-transliteration/hi.translit.sampled.train.tsv', src_vocab, tgt_vocab)\n",
    "    dv = TransliterationDataset('/kaggle/input/lexicons-hindi-transliteration/hi.translit.sampled.dev.tsv', src_vocab, tgt_vocab)\n",
    "    dl = DataLoader(ds, batch_size=cfg.batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "    val_dl = DataLoader(dv, batch_size=cfg.batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    # model\n",
    "    enc = Encoder(len(src_vocab), cfg.emb_dim, cfg.hid_dim, cfg.enc_layers, cfg.cell_type, cfg.dropout)\n",
    "    dec = Decoder(len(tgt_vocab), cfg.emb_dim, cfg.hid_dim, cfg.dec_layers, cfg.cell_type, cfg.dropout, False)\n",
    "    model = Seq2Seq(enc,dec,pad_idx,device).to(device)\n",
    "    opt   = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "    crit  = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "    for epoch in range(1, 11):\n",
    "        tr_loss, tr_acc = train_epoch(model, dl, opt, crit, pad_idx)\n",
    "        vl_loss, vl_acc = eval_epoch(model, val_dl, crit, cfg.beam_size, pad_idx)\n",
    "        wandb.log({\n",
    "            'epoch':       epoch,\n",
    "            'train_loss':  tr_loss,\n",
    "            'train_acc':   tr_acc,\n",
    "            'val_loss':    vl_loss,\n",
    "            'val_acc':     vl_acc\n",
    "        })\n",
    "            \n",
    "    # save best\n",
    "    torch.save(model.state_dict(),'model_without_attn.pt')\n",
    "    wandb.save('model_without_attn.pt')\n",
    "\n",
    "if __name__=='__main__':\n",
    "    sweep_id = wandb.sweep(sweep_config, project='dakshina-translit')\n",
    "    wandb.agent(sweep_id, function=sweep_run, count=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0252d49c",
   "metadata": {
    "papermill": {
     "duration": 0.048845,
     "end_time": "2025-05-20T07:07:10.808801",
     "exception": false,
     "start_time": "2025-05-20T07:07:10.759956",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d584c9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T07:07:10.897838Z",
     "iopub.status.busy": "2025-05-20T07:07:10.897612Z",
     "iopub.status.idle": "2025-05-20T07:07:10.909023Z",
     "shell.execute_reply": "2025-05-20T07:07:10.908185Z"
    },
    "papermill": {
     "duration": 0.057372,
     "end_time": "2025-05-20T07:07:10.910228",
     "exception": false,
     "start_time": "2025-05-20T07:07:10.852856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parameters and shapes:\n",
      "\n",
      "enc.emb.weight                           → (29, 16)\n",
      "enc.rnn.weight_ih_l0                     → (1024, 16)\n",
      "enc.rnn.weight_hh_l0                     → (1024, 256)\n",
      "enc.rnn.bias_ih_l0                       → (1024,)\n",
      "enc.rnn.bias_hh_l0                       → (1024,)\n",
      "enc.rnn.weight_ih_l1                     → (1024, 256)\n",
      "enc.rnn.weight_hh_l1                     → (1024, 256)\n",
      "enc.rnn.bias_ih_l1                       → (1024,)\n",
      "enc.rnn.bias_hh_l1                       → (1024,)\n",
      "dec.emb.weight                           → (66, 16)\n",
      "dec.rnn.weight_ih_l0                     → (1024, 16)\n",
      "dec.rnn.weight_hh_l0                     → (1024, 256)\n",
      "dec.rnn.bias_ih_l0                       → (1024,)\n",
      "dec.rnn.bias_hh_l0                       → (1024,)\n",
      "dec.fc.weight                            → (66, 256)\n",
      "dec.fc.bias                              → (66,)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. Load the saved state dict\n",
    "state_dict = torch.load('model_without_attn.pt', map_location='cpu')\n",
    "\n",
    "# 2. Print every parameter name and its shape\n",
    "print(\"Saved parameters and shapes:\\n\")\n",
    "for name, tensor in state_dict.items():\n",
    "    print(f\"{name:40s} → {tuple(tensor.shape)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a6b08ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T07:07:11.027871Z",
     "iopub.status.busy": "2025-05-20T07:07:11.027314Z",
     "iopub.status.idle": "2025-05-20T07:07:11.031097Z",
     "shell.execute_reply": "2025-05-20T07:07:11.030582Z"
    },
    "papermill": {
     "duration": 0.051565,
     "end_time": "2025-05-20T07:07:11.032089",
     "exception": false,
     "start_time": "2025-05-20T07:07:10.980524",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Paths and device\n",
    "# test_path = '/kaggle/input/transliteration-9123/hi.translit.sampled.test.tsv'\n",
    "# device    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# pad_idx   = tgt_vocab['<pad>']\n",
    "\n",
    "# # 1. Prepare test DataLoader\n",
    "# test_dataset = TransliterationDataset(test_path, src_vocab, tgt_vocab)\n",
    "# test_loader  = DataLoader(test_dataset, batch_size=128, collate_fn=collate_fn)\n",
    "\n",
    "# # 2. Re‐create the model with best hyperparameters\n",
    "# #    Replace these values with your actual best config\n",
    "# best_emb_dim    = 256\n",
    "# best_hid_dim    = 256\n",
    "# best_enc_layers = 1\n",
    "# best_dec_layers = 1\n",
    "# best_cell_type  = 'LSTM'\n",
    "# best_dropout    = 0.3\n",
    "\n",
    "\n",
    "# enc = Encoder(len(src_vocab), best_emb_dim, best_hid_dim,\n",
    "#               best_enc_layers, best_cell_type, best_dropout)\n",
    "# dec = Decoder(len(tgt_vocab), best_emb_dim, best_hid_dim,\n",
    "#               best_dec_layers, best_cell_type, best_dropout,\n",
    "#               use_attn=False)\n",
    "# model = Seq2Seq(enc, dec, pad_idx, device).to(device)\n",
    "\n",
    "# # 3. Load the saved weights\n",
    "# model.load_state_dict(torch.load('model_use_attn.pt', map_location=device))\n",
    "# model.eval()\n",
    "\n",
    "# # 4. Define the loss criterion\n",
    "# criterion = torch.nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "# dv = TransliterationDataset('/kaggle/input/transliteration-9123/hi.translit.sampled.dev.tsv', src_vocab, tgt_vocab)\n",
    "# val_dl = DataLoader(dv, batch_size=128, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# # 5. Run evaluation on the test set\n",
    "# test_loss, test_acc = eval_epoch(model, test_loader, criterion,\n",
    "#                                  beam_k=1, pad_idx=pad_idx)\n",
    "\n",
    "# print(f\"Test Loss: {test_loss:.4f}\")\n",
    "# print(f\"Test Token‐level Accuracy: {test_acc:.4%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1d62478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-20T07:07:11.121706Z",
     "iopub.status.busy": "2025-05-20T07:07:11.121526Z",
     "iopub.status.idle": "2025-05-20T07:07:11.125438Z",
     "shell.execute_reply": "2025-05-20T07:07:11.124524Z"
    },
    "papermill": {
     "duration": 0.050231,
     "end_time": "2025-05-20T07:07:11.126747",
     "exception": false,
     "start_time": "2025-05-20T07:07:11.076516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# def sweep_run():\n",
    "#     wandb.init()\n",
    "#     cfg = wandb.config\n",
    "    \n",
    "#     # data\n",
    "#     ds = TransliterationDataset('/kaggle/input/transliteration-9123/hi.translit.sampled.train.tsv', src_vocab, tgt_vocab)\n",
    "#     dv = TransliterationDataset('/kaggle/input/transliteration-9123/hi.translit.sampled.dev.tsv', src_vocab, tgt_vocab)\n",
    "#     dl = DataLoader(ds, batch_size=cfg.batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "#     val_dl = DataLoader(dv, batch_size=cfg.batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "#     # model\n",
    "#     enc = Encoder(len(src_vocab), cfg.emb_dim, cfg.hid_dim, cfg.enc_layers, cfg.cell_type, cfg.dropout)\n",
    "#     dec = Decoder(len(tgt_vocab), cfg.emb_dim, cfg.hid_dim, cfg.dec_layers, cfg.cell_type, cfg.dropout, use_attn=False)\n",
    "#     model = Seq2Seq(enc,dec,pad_idx,device).to(device)\n",
    "#     opt   = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "#     crit  = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "\n",
    "#     for epoch in range(1, 11):\n",
    "#         tr_loss, tr_acc = train_epoch(model, dl, opt, crit, pad_idx)\n",
    "#         vl_loss, vl_acc = eval_epoch(model, val_dl, crit, cfg.beam_size, pad_idx)\n",
    "#         wandb.log({\n",
    "#             'epoch':       epoch,\n",
    "#             'train_loss':  tr_loss,\n",
    "#             'train_acc':   tr_acc,\n",
    "#             'val_loss':    vl_loss,\n",
    "#             'val_acc':     vl_acc\n",
    "#         })\n",
    "            \n",
    "#     # save best\n",
    "#     torch.save(model.state_dict(),'model.pt')\n",
    "#     wandb.save('model.pt')\n",
    "\n",
    "# if __name__=='__main__':\n",
    "#     sweep_id = wandb.sweep(sweep_config, project='dakshina-translit')\n",
    "#     wandb.agent(sweep_id, function=sweep_run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f73dfd",
   "metadata": {
    "papermill": {
     "duration": 0.045037,
     "end_time": "2025-05-20T07:07:11.216063",
     "exception": false,
     "start_time": "2025-05-20T07:07:11.171026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d120b88",
   "metadata": {
    "papermill": {
     "duration": 0.04386,
     "end_time": "2025-05-20T07:07:11.303839",
     "exception": false,
     "start_time": "2025-05-20T07:07:11.259979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8281247",
   "metadata": {
    "papermill": {
     "duration": 0.044016,
     "end_time": "2025-05-20T07:07:11.392250",
     "exception": false,
     "start_time": "2025-05-20T07:07:11.348234",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CHECK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d330bc7",
   "metadata": {
    "papermill": {
     "duration": 0.043963,
     "end_time": "2025-05-20T07:07:11.480472",
     "exception": false,
     "start_time": "2025-05-20T07:07:11.436509",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7452284,
     "sourceId": 11859762,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7465559,
     "sourceId": 11879116,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5679.387828,
   "end_time": "2025-05-20T07:07:14.586870",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-20T05:32:35.199042",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
