{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11859762,"sourceType":"datasetVersion","datasetId":7452284},{"sourceId":11879116,"sourceType":"datasetVersion","datasetId":7465559}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":28601.684445,"end_time":"2025-05-20T05:09:00.919352","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-19T21:12:19.234907","version":"2.6.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --upgrade pip\n!pip install tensorflow wandb numpy pandas tqdm","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2025-05-20T21:20:12.275622Z","iopub.execute_input":"2025-05-20T21:20:12.275792Z","iopub.status.idle":"2025-05-20T21:20:20.611154Z","shell.execute_reply.started":"2025-05-20T21:20:12.275776Z","shell.execute_reply":"2025-05-20T21:20:20.610102Z"},"papermill":{"duration":8.267,"end_time":"2025-05-19T21:12:32.270446","exception":false,"start_time":"2025-05-19T21:12:24.003446","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\nCollecting pip\n  Downloading pip-25.1.1-py3-none-any.whl.metadata (3.6 kB)\nDownloading pip-25.1.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pip\n  Attempting uninstall: pip\n    Found existing installation: pip 24.1.2\n    Uninstalling pip-24.1.2:\n      Successfully uninstalled pip-24.1.2\nSuccessfully installed pip-25.1.1\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.9)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.8)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.4)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.25.1)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.5)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3->wandb) (0.4.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import wandb\nwandb.login(key='613aac3388325cb6206db61e3c1a38a707589743')","metadata":{"execution":{"iopub.status.busy":"2025-05-20T21:20:20.614772Z","iopub.execute_input":"2025-05-20T21:20:20.615045Z","iopub.status.idle":"2025-05-20T21:20:29.373815Z","shell.execute_reply.started":"2025-05-20T21:20:20.615010Z","shell.execute_reply":"2025-05-20T21:20:29.373119Z"},"papermill":{"duration":3.626058,"end_time":"2025-05-19T21:12:35.900977","exception":false,"start_time":"2025-05-19T21:12:32.274919","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mda24s006\u001b[0m (\u001b[33mda24s006-indian-institue-of-technology-madras-\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"# Data Preparation:\n- downloading and extracting dikshina hindi lexicon: already downloaded and uploaded the relavant part of the data in the kaggle environment.\n- building character vocabularies and dataloader.","metadata":{"papermill":{"duration":0.003775,"end_time":"2025-05-19T21:12:35.908942","exception":false,"start_time":"2025-05-19T21:12:35.905167","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# data_utils.py\nimport pandas as pd\nimport torch\nfrom torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import Dataset\n\ndef build_vocab(pairs, specials=['<pad>','<sos>','<eos>']):\n    chars = set(''.join(pairs))\n    idx = {tok:i for i,tok in enumerate(specials)}\n    for c in sorted(chars):\n        idx[c] = len(idx)\n    return idx\n\nclass TransliterationDataset(Dataset):\n    def __init__(self, path, src_vocab, tgt_vocab, max_len=32):\n        df = pd.read_csv(path, sep='\\t', names=['devanagari','roman','dont_care'])\n        df = df.dropna()\n        self.pairs = df[['roman','devanagari']].values.tolist()\n        self.src_vocab, self.tgt_vocab = src_vocab, tgt_vocab\n        self.max_len = max_len\n\n    def __len__(self): return len(self.pairs)\n\n    def __getitem__(self, i):\n        src, tgt = self.pairs[i]\n        # src: [c1,c2,...] -> [..., <eos>]\n        src_ids = [self.src_vocab[c] for c in src][:self.max_len] + [self.src_vocab['<eos>']]\n        # tgt: [<sos>, c1,c2,..., <eos>]\n        tgt_ids = [self.tgt_vocab['<sos>']] + \\\n                  [self.tgt_vocab[c] for c in tgt][:self.max_len] + \\\n                  [self.tgt_vocab['<eos>']]\n        return torch.tensor(src_ids, dtype=torch.long), torch.tensor(tgt_ids, dtype=torch.long)\n\ndef collate_fn(batch):\n    srcs, tgts = zip(*batch)\n    srcs_p = pad_sequence(srcs, batch_first=True, padding_value=src_vocab['<pad>'])\n    tgts_p = pad_sequence(tgts, batch_first=True, padding_value=tgt_vocab['<pad>'])\n    return srcs_p, tgts_p\n\n# Build vocabs once\ndf = pd.read_csv('/kaggle/input/lexicons-hindi-transliteration/hi.translit.sampled.train.tsv', sep='\\t', names=['devanagari','roman','dont_care'])\ndf = df.dropna()\nsrc_vocab = build_vocab(df['roman'])\ntgt_vocab = build_vocab(df['devanagari'])","metadata":{"execution":{"iopub.status.busy":"2025-05-20T21:20:29.375241Z","iopub.execute_input":"2025-05-20T21:20:29.375584Z","iopub.status.idle":"2025-05-20T21:20:34.083494Z","shell.execute_reply.started":"2025-05-20T21:20:29.375564Z","shell.execute_reply":"2025-05-20T21:20:34.082702Z"},"papermill":{"duration":6.574017,"end_time":"2025-05-19T21:12:42.486772","exception":false,"start_time":"2025-05-19T21:12:35.912755","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Model Definition\n- Encoder and Decoder class","metadata":{"papermill":{"duration":0.003878,"end_time":"2025-05-19T21:12:42.495050","exception":false,"start_time":"2025-05-19T21:12:42.491172","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# model.py\nimport torch, torch.nn as nn, torch.nn.functional as F\n\nclass Encoder(nn.Module):\n    \n    def __init__(self, inp_dim, emb_dim, hid_dim, n_layers, cell, dropout):\n        super().__init__()\n        self.emb = nn.Embedding(inp_dim, emb_dim)\n        RNN = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell]\n        self.rnn = RNN(emb_dim, hid_dim, n_layers,\n                       dropout=dropout if n_layers>1 else 0,\n                       batch_first=True)\n        self.drop = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        # x: [B, S]\n        e = self.drop(self.emb(x))\n        out, hidden = self.rnn(e)\n        return out, hidden\n\nclass Attention(nn.Module):\n    \n    def __init__(self, hid_dim):\n        super().__init__()\n        self.attn = nn.Linear(hid_dim*2, hid_dim)\n        self.v    = nn.Linear(hid_dim, 1, bias=False)\n        \n    def forward(self, hidden, enc_out):\n        # hidden: [B, H], enc_out: [B, S, H]\n        B, S, H = enc_out.size()\n        h = hidden.unsqueeze(1).repeat(1,S,1)               # [B,S,H]\n        energy = torch.tanh(self.attn(torch.cat([h,enc_out],dim=2)))  # [B,S,H]\n        scores = self.v(energy).squeeze(2)                  # [B,S]\n        return F.softmax(scores, dim=1)\n\nclass Decoder(nn.Module):\n    \n    def __init__(self, out_dim, emb_dim, hid_dim, n_layers, cell, dropout, use_attn=False):\n        super().__init__()\n        self.emb = nn.Embedding(out_dim, emb_dim)\n        RNN = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell]\n        self.rnn = RNN(emb_dim + (hid_dim if use_attn else 0),\n                       hid_dim, n_layers,\n                       dropout=dropout if n_layers>1 else 0,\n                       batch_first=True)\n        self.fc  = nn.Linear(hid_dim, out_dim)\n        self.drop = nn.Dropout(dropout)\n        self.use_attn = use_attn\n        if use_attn: self.attn = Attention(hid_dim)\n\n    def forward(self, tgt_tok, hidden, enc_out=None):\n        # tgt_tok: [B], hidden: (h_n, c_n)? or h_n\n        B = tgt_tok.size(0)\n        t = tgt_tok.unsqueeze(1)            # [B,1]\n        emb = self.drop(self.emb(t))        # [B,1,E]\n        \n        if self.use_attn:\n            h = hidden[-1] if not isinstance(hidden, tuple) else hidden[0][-1]\n            attn_w = self.attn(h, enc_out)  # [B, S]\n            ctx    = torch.bmm(attn_w.unsqueeze(1), enc_out)  # [B,1,H]\n            rnn_in = torch.cat([emb, ctx], dim=2)\n        else:\n            rnn_in = emb\n        out, hidden = self.rnn(rnn_in, hidden)\n        pred = self.fc(out.squeeze(1))      # [B, out_dim]\n        \n        return pred, hidden, (attn_w if self.use_attn else None)\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, enc, dec, pad_idx, device):\n        super().__init__()\n        self.enc, self.dec = enc, dec\n        self.pad_idx = pad_idx\n        self.device  = device\n\n    # def _init_decoder_hidden(self, enc_hidden):\n    #     # Handles both GRU (Tensor) and LSTM (tuple) encoder hidden states\n    #     if isinstance(enc_hidden, tuple):  # LSTM: (h_n, c_n)\n    #         h, c = enc_hidden\n    #         dec_layers = self.dec.rnn.num_layers\n    #         B, H = h.size(1), h.size(2)\n    #         # Prepare zero-padded states\n    #         h0 = torch.zeros(dec_layers, B, H, device=self.device)\n    #         c0 = torch.zeros(dec_layers, B, H, device=self.device)\n    #         # Copy encoder layers into decoder state\n    #         h0[:h.size(0)] = h\n    #         c0[:c.size(0)] = c\n    #         return (h0, c0)\n    #     else:  # GRU or RNN\n    #         h = enc_hidden\n    #         dec_layers = self.dec.rnn.num_layers\n    #         B, H = h.size(1), h.size(2)\n    #         h0 = torch.zeros(dec_layers, B, H, device=self.device)\n    #         h0[:h.size(0)] = h\n    #         return h0\n\n    def _init_decoder_hidden(self, enc_hidden):\n       \n        dec_layers = self.dec.rnn.num_layers\n    \n        if isinstance(enc_hidden, tuple):  # LSTM: (h, c)\n            h, c = enc_hidden\n            enc_layers, B, H = h.size()\n            # Prepare zero states\n            h0 = torch.zeros(dec_layers,  B, H, device=self.device)\n            c0 = torch.zeros(dec_layers,  B, H, device=self.device)\n            # Number of layers to copy\n            n = min(enc_layers, dec_layers)\n            # Copy last n layers from encoder into bottom of decoder state\n            h0[-n:] = h[-n:]\n            c0[-n:] = c[-n:]\n            return (h0, c0)\n\n        else:  # GRU or vanilla RNN\n            h = enc_hidden\n            enc_layers, B, H = h.size()\n            h0 = torch.zeros(dec_layers, B, H, device=self.device)\n            n = min(enc_layers, dec_layers)\n            h0[-n:] = h[-n:]\n            return h0\n\n\n    def forward(self, src, tgt, teacher_forcing=0.5):\n        B, T = tgt.size()\n        out_dim = self.dec.fc.out_features\n        outputs = torch.zeros(B, T, out_dim, device=self.device)\n\n        enc_out, enc_hidden = self.enc(src)\n        # Initialize decoder hidden state to match dec_layers\n        dec_hidden = self._init_decoder_hidden(enc_hidden)\n\n        inp = tgt[:,0]  # <sos>\n        for t in range(1, T):\n            pred, dec_hidden, _ = self.dec(\n                inp, dec_hidden,\n                enc_out if self.dec.use_attn else None\n            )\n            outputs[:,t] = pred\n            top1 = pred.argmax(1)\n            inp = tgt[:,t] if torch.rand(1).item() < teacher_forcing else top1\n\n        return outputs\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T21:20:34.084320Z","iopub.execute_input":"2025-05-20T21:20:34.084584Z","iopub.status.idle":"2025-05-20T21:20:34.100701Z","shell.execute_reply.started":"2025-05-20T21:20:34.084561Z","shell.execute_reply":"2025-05-20T21:20:34.100086Z"},"papermill":{"duration":0.021747,"end_time":"2025-05-19T21:12:42.520600","exception":false,"start_time":"2025-05-19T21:12:42.498853","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# Beam Search Decoding","metadata":{"papermill":{"duration":0.003735,"end_time":"2025-05-19T21:12:42.528106","exception":false,"start_time":"2025-05-19T21:12:42.524371","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# beam_search.py\nimport torch, torch.nn.functional as F\nfrom queue import PriorityQueue\nfrom math import log\n\nclass BeamNode:\n    def __init__(self, hidden, prev, tok, logp, length):\n        self.hidden, self.prev, self.tok = hidden, prev, tok\n        self.logp, self.len = logp, length\n    def score(self): return self.logp / float(self.len)\n\ndef beam_decode(model, src, src_vocab, tgt_vocab, beam_k=3, max_len=32, device='cpu'):\n    model.eval()\n    with torch.no_grad():\n        enc_out, hidden = model.enc(src)\n        # init beam\n        init_tok = torch.tensor([tgt_vocab['<sos>']], device=device)\n        node = BeamNode(hidden, None, init_tok, 0.0, 1)\n        pq = PriorityQueue(); pq.put((-node.score(), node))\n        end_beams = []\n        while not pq.empty():\n            _, n = pq.get()\n            if n.tok.item()==tgt_vocab['<eos>'] and n.prev is not None:\n                end_beams.append((n.score(), n))\n                if len(end_beams)>=beam_k: break\n            inp = n.tok\n            pred, hid, _ = model.dec(inp, n.hidden, enc_out if model.dec.use_attn else None)\n            logps = F.log_softmax(pred, dim=1)\n            topv, topi = logps.topk(beam_k)\n            for i in range(beam_k):\n                tok_i = topi[0][i].unsqueeze(0)\n                score = n.logp + topv[0][i].item()\n                new_node = BeamNode(hid, n, tok_i, score, n.len+1)\n                pq.put((-new_node.score(), new_node))\n        # backtrack best\n        best = sorted(end_beams, key=lambda x: x[0], reverse=True)[0][1]\n        seq = []\n        while best.prev is not None:\n            seq.append(best.tok.item()); best = best.prev\n        return seq[::-1]\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T21:20:34.101467Z","iopub.execute_input":"2025-05-20T21:20:34.101829Z","iopub.status.idle":"2025-05-20T21:20:34.156434Z","shell.execute_reply.started":"2025-05-20T21:20:34.101799Z","shell.execute_reply":"2025-05-20T21:20:34.155727Z"},"papermill":{"duration":0.013476,"end_time":"2025-05-19T21:12:42.545390","exception":false,"start_time":"2025-05-19T21:12:42.531914","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# 4. Training, Evaluation & W&B Sweep","metadata":{"papermill":{"duration":0.003631,"end_time":"2025-05-19T21:12:42.552903","exception":false,"start_time":"2025-05-19T21:12:42.549272","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# train.py\nimport wandb, torch, torch.optim as optim, torch.nn as nn\n# from data_utils import TransliterationDataset, collate_fn, src_vocab, tgt_vocab\n# from model import Encoder, Decoder, Seq2Seq\n# from beam_search import beam_decode\nfrom torch.utils.data import DataLoader\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npad_idx = tgt_vocab['<pad>']\n\nsweep_config = {\n  'method': 'bayes',\n  'metric': {'name':'val_loss','goal':'minimize'},\n  'parameters':{\n    'emb_dim':   {'values':[32]},\n    'hid_dim':   {'values':[256]},\n    'enc_layers':{'values':[3]},\n    'dec_layers':{'values':[3]},\n    'cell_type': {'values':['LSTM']},\n    'dropout':   {'values':[0.2]},\n    'beam_size': {'values':[5]},\n    'lr':        {'value':1e-3},\n    'batch_size':{'value':128}\n  }\n}","metadata":{"execution":{"iopub.status.busy":"2025-05-20T21:20:49.229977Z","iopub.execute_input":"2025-05-20T21:20:49.230699Z","iopub.status.idle":"2025-05-20T21:20:49.320018Z","shell.execute_reply.started":"2025-05-20T21:20:49.230672Z","shell.execute_reply":"2025-05-20T21:20:49.319230Z"},"papermill":{"duration":0.09488,"end_time":"2025-05-19T21:12:42.651689","exception":false,"start_time":"2025-05-19T21:12:42.556809","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"\n# def train_epoch(model, loader, opt, crit):\n#     model.train(); total=0\n#     for src, tgt in loader:\n#         src, tgt = src.to(device), tgt.to(device)\n#         opt.zero_grad()\n#         out = model(src, tgt,teacher_forcing=0.5)\n#         loss = crit(out[:,1:].reshape(-1,out.size(-1)), tgt[:,1:].reshape(-1))\n#         loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(),1)\n#         opt.step(); total += loss.item()\n#     return total/len(loader)\n\n# def eval_epoch(model, loader, crit, beam_k):\n#     model.eval(); total=0\n#     with torch.no_grad():\n#         for src,tgt in loader:\n#             src,tgt = src.to(device), tgt.to(device)\n#             # teacher_forced loss\n#             out = model(src,tgt,teacher_forcing=0.0)\n#             total += crit(out[:,1:].reshape(-1,out.size(-1)), tgt[:,1:].reshape(-1)).item()\n#     return total/len(loader)\n\ndef calculate_accuracy(output, target, pad_idx):\n    # output: [B, T, V], target: [B, T]\n    with torch.no_grad():\n        pred_tokens = output.argmax(dim=2)           # [B, T]\n        mask        = target != pad_idx              # ignore pads\n        correct     = (pred_tokens == target) & mask\n        return correct.sum().float() / mask.sum().float()\n\ndef train_epoch(model, loader, opt, crit, pad_idx):\n    model.train()\n    total_loss = 0\n    total_acc  = 0\n    for src, tgt in loader:\n        src, tgt = src.to(device), tgt.to(device)\n        opt.zero_grad()\n        out  = model(src, tgt, teacher_forcing=0.5)\n        loss = crit(out[:,1:].reshape(-1,out.size(-1)), tgt[:,1:].reshape(-1))\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n        opt.step()\n\n        total_loss += loss.item()\n        total_acc  += calculate_accuracy(out[:,1:], tgt[:,1:], pad_idx)\n    return total_loss/len(loader), total_acc/len(loader)\n\ndef eval_epoch(model, loader, crit, beam_k, pad_idx):\n    model.eval()\n    total_loss = 0\n    total_acc  = 0\n    with torch.no_grad():\n        for src, tgt in loader:\n            src, tgt = src.to(device), tgt.to(device)\n            out  = model(src, tgt, teacher_forcing=0.0)\n            loss = crit(out[:,1:].reshape(-1,out.size(-1)), tgt[:,1:].reshape(-1))\n\n            total_loss += loss.item()\n            total_acc  += calculate_accuracy(out[:,1:], tgt[:,1:], pad_idx)\n    return total_loss/len(loader), total_acc/len(loader)\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T21:20:51.304866Z","iopub.execute_input":"2025-05-20T21:20:51.305115Z","iopub.status.idle":"2025-05-20T21:20:51.313384Z","shell.execute_reply.started":"2025-05-20T21:20:51.305096Z","shell.execute_reply":"2025-05-20T21:20:51.312761Z"},"papermill":{"duration":0.014446,"end_time":"2025-05-19T21:12:42.670588","exception":false,"start_time":"2025-05-19T21:12:42.656142","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"\ndef sweep_run():\n    wandb.init()\n    cfg = wandb.config\n    \n    # data\n    ds = TransliterationDataset('/kaggle/input/lexicons-hindi-transliteration/hi.translit.sampled.train.tsv', src_vocab, tgt_vocab)\n    dv = TransliterationDataset('/kaggle/input/lexicons-hindi-transliteration/hi.translit.sampled.dev.tsv', src_vocab, tgt_vocab)\n    dl = DataLoader(ds, batch_size=cfg.batch_size, collate_fn=collate_fn, shuffle=True)\n    val_dl = DataLoader(dv, batch_size=cfg.batch_size, collate_fn=collate_fn)\n    \n    # model\n    enc = Encoder(len(src_vocab), cfg.emb_dim, cfg.hid_dim, cfg.enc_layers, cfg.cell_type, cfg.dropout)\n    dec = Decoder(len(tgt_vocab), cfg.emb_dim, cfg.hid_dim, cfg.dec_layers, cfg.cell_type, cfg.dropout, False)\n    model = Seq2Seq(enc,dec,pad_idx,device).to(device)\n    opt   = optim.Adam(model.parameters(), lr=cfg.lr)\n    crit  = nn.CrossEntropyLoss(ignore_index=pad_idx)\n\n    for epoch in range(1, 11):\n        tr_loss, tr_acc = train_epoch(model, dl, opt, crit, pad_idx)\n        vl_loss, vl_acc = eval_epoch(model, val_dl, crit, cfg.beam_size, pad_idx)\n        wandb.log({\n            'epoch':       epoch,\n            'train_loss':  tr_loss,\n            'train_acc':   tr_acc,\n            'val_loss':    vl_loss,\n            'val_acc':     vl_acc\n        })\n            \n    # save best\n    torch.save(model.state_dict(),'model_without_attn.pt')\n    wandb.save('model_without_attn.pt')\n\nif __name__=='__main__':\n    sweep_id = wandb.sweep(sweep_config, project='dakshina-translit')\n    wandb.agent(sweep_id, function=sweep_run, count=1)\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T21:20:54.854294Z","iopub.execute_input":"2025-05-20T21:20:54.855004Z","iopub.status.idle":"2025-05-20T21:23:25.079165Z","shell.execute_reply.started":"2025-05-20T21:20:54.854979Z","shell.execute_reply":"2025-05-20T21:23:25.078480Z"},"papermill":{"duration":28570.231641,"end_time":"2025-05-20T05:08:52.906305","exception":false,"start_time":"2025-05-19T21:12:42.674664","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Create sweep with ID: j7f76ovx\nSweep URL: https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/j7f76ovx\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: yjvkc79p with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \thid_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_212102-yjvkc79p</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/yjvkc79p' target=\"_blank\">zany-sweep-1</a></strong> to <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/j7f76ovx' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/j7f76ovx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/j7f76ovx' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/sweeps/j7f76ovx</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/yjvkc79p' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/yjvkc79p</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_acc</td><td>▁▂▄▆▇▇▇███</td></tr><tr><td>train_loss</td><td>█▆▄▃▂▂▂▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_acc</td><td>0.84443</td></tr><tr><td>train_loss</td><td>0.51967</td></tr><tr><td>val_acc</td><td>0.72391</td></tr><tr><td>val_loss</td><td>1.01327</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">zany-sweep-1</strong> at: <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/yjvkc79p' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit/runs/yjvkc79p</a><br> View project at: <a href='https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit' target=\"_blank\">https://wandb.ai/da24s006-indian-institue-of-technology-madras-/dakshina-translit</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_212102-yjvkc79p/logs</code>"},"metadata":{}}],"execution_count":9},{"cell_type":"markdown","source":"# test set predictions","metadata":{"papermill":{"duration":0.176435,"end_time":"2025-05-20T05:08:53.256148","exception":false,"start_time":"2025-05-20T05:08:53.079713","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Paths and device\ntest_path = '/kaggle/input/transliteration-9123/hi.translit.sampled.test.tsv'\ndevice    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npad_idx   = tgt_vocab['<pad>']\n\n# 1. Prepare test DataLoader\ntest_dataset = TransliterationDataset(test_path, src_vocab, tgt_vocab)\ntest_loader  = DataLoader(test_dataset, batch_size=128, collate_fn=collate_fn)\n\n# 2. Re‐create the model with best hyperparameters\n#    Replace these values with your actual best config\nbest_emb_dim    = 32\nbest_hid_dim    = 256\nbest_enc_layers = 3\nbest_dec_layers = 3\nbest_cell_type  = 'LSTM'\nbest_dropout    = 0.2\n\n\nenc = Encoder(len(src_vocab), best_emb_dim, best_hid_dim,\n              best_enc_layers, best_cell_type, best_dropout)\ndec = Decoder(len(tgt_vocab), best_emb_dim, best_hid_dim,\n              best_dec_layers, best_cell_type, best_dropout,\n              use_attn=False)\nmodel = Seq2Seq(enc, dec, pad_idx, device).to(device)\n\n# 3. Load the saved weights\nmodel.load_state_dict(torch.load('model_without_attn.pt', map_location=device))\nmodel.eval()\n\n# 4. Define the loss criterion\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=pad_idx)\n\ndv = TransliterationDataset('/kaggle/input/transliteration-9123/hi.translit.sampled.dev.tsv', src_vocab, tgt_vocab)\nval_dl = DataLoader(dv, batch_size=128, collate_fn=collate_fn)\n\n\n# 5. Run evaluation on the test set\ntest_loss, test_acc = eval_epoch(model, test_loader, criterion,\n                                 beam_k=1, pad_idx=pad_idx)\n\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Token‐level Accuracy: {test_acc:.4%}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T21:24:43.719598Z","iopub.execute_input":"2025-05-20T21:24:43.720163Z","iopub.status.idle":"2025-05-20T21:24:44.200080Z","shell.execute_reply.started":"2025-05-20T21:24:43.720139Z","shell.execute_reply":"2025-05-20T21:24:44.199297Z"},"papermill":{"duration":0.179443,"end_time":"2025-05-20T05:08:53.998525","exception":false,"start_time":"2025-05-20T05:08:53.819082","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Test Loss: 1.0145\nTest Token‐level Accuracy: 71.7935%\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\n\n# Paths and device\ntest_path = '/kaggle/input/transliteration-9123/hi.translit.sampled.test.tsv'\ndevice    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\npad_idx   = tgt_vocab['<pad>']\n\n# Define the modified eval_epoch function\ndef eval_epoch(model, loader, crit, beam_k, pad_idx, output_file=None):\n    model.eval()\n    total_loss = 0\n    total_token_acc = 0\n    all_predictions = []\n    all_references = []\n    \n    with torch.no_grad():\n        for src, tgt in loader:\n            src, tgt = src.to(device), tgt.to(device)\n            \n            # Get references for accuracy calculation\n            for i in range(tgt.size(0)):\n                ref_seq = []\n                for idx in tgt[i][1:].cpu().tolist():  # skip <sos>\n                    if idx == tgt_vocab['<eos>']:\n                        break\n                    ref_seq.append(next(ch for ch,v in tgt_vocab.items() if v==idx))\n                all_references.append(''.join(ref_seq))\n            \n            # Calculate loss (teacher forcing = 0)\n            out = model(src, tgt[:, :-1])\n            loss = crit(out.reshape(-1, out.size(-1)), tgt[:, 1:].reshape(-1))\n            total_loss += loss.item()\n            \n            # Calculate token-level accuracy\n            pred_tokens = out.argmax(dim=-1)\n            mask = tgt[:, 1:] != pad_idx\n            correct_tokens = (pred_tokens == tgt[:, 1:]) & mask\n            total_token_acc += correct_tokens.sum().item() / mask.sum().item() if mask.sum().item() > 0 else 0\n            \n            # Generate predictions using greedy decoding\n            enc_out, enc_h = model.enc(src)\n            dec_h = model._init_decoder_hidden(enc_h)\n            inp = tgt[:, 0]  # <sos>\n            \n            # Decode one step at a time\n            batch_size = src.size(0)\n            max_len = 100  # reasonable upper bound\n            preds = torch.zeros(batch_size, max_len, dtype=torch.long, device=device)\n            \n            for t in range(max_len):\n                # Pass None for encoder_outputs since this is no-attention model\n                logits, dec_h, _ = model.dec(inp, dec_h, None)\n                next_token = logits.argmax(dim=1)\n                preds[:, t] = next_token\n                inp = next_token\n                \n                # Stop if all sequences have predicted <eos>\n                if (next_token == tgt_vocab['<eos>']).sum() == batch_size:\n                    break\n            \n            # Convert token IDs to text\n            for i in range(batch_size):\n                pred_seq = []\n                for idx in preds[i].cpu().tolist():\n                    if idx == tgt_vocab['<eos>']:\n                        break\n                    pred_seq.append(next(ch for ch,v in tgt_vocab.items() if v==idx))\n                all_predictions.append(''.join(pred_seq))\n    \n    # Calculate character-level accuracy\n    char_matches = 0\n    total_chars = sum(len(ref) for ref in all_references)\n    \n    for pred, ref in zip(all_predictions, all_references):\n        for p_char, r_char in zip(pred, ref):\n            if p_char == r_char:\n                char_matches += 1\n    \n    # Calculate word-level accuracy\n    word_matches = sum(pred == ref for pred, ref in zip(all_predictions, all_references))\n    total_words = len(all_references)\n    \n    char_acc = char_matches / total_chars if total_chars > 0 else 0\n    word_acc = word_matches / total_words if total_words > 0 else 0\n    \n    # Save predictions to file if specified\n    if output_file:\n        with open(output_file, 'w', encoding='utf-8') as f:\n            for pred in all_predictions:\n                f.write(pred + '\\n')\n        print(f\"Saved {len(all_predictions)} predictions to {output_file}\")\n    \n    return total_loss/len(loader), total_token_acc/len(loader), char_acc, word_acc, all_predictions\n\n# 1. Prepare test DataLoader\ntest_dataset = TransliterationDataset(test_path, src_vocab, tgt_vocab)\ntest_loader  = DataLoader(test_dataset, batch_size=128, collate_fn=collate_fn)\n\n# 2. Re‐create the model with best hyperparameters\n#    Replace these values with your actual best config\nbest_emb_dim    = 32\nbest_hid_dim    = 256\nbest_enc_layers = 3\nbest_dec_layers = 3\nbest_cell_type  = 'LSTM'\nbest_dropout    = 0.2\n\nenc = Encoder(len(src_vocab), best_emb_dim, best_hid_dim,\n              best_enc_layers, best_cell_type, best_dropout)\ndec = Decoder(len(tgt_vocab), best_emb_dim, best_hid_dim,\n              best_dec_layers, best_cell_type, best_dropout,\n              use_attn=False)\nmodel = Seq2Seq(enc, dec, pad_idx, device).to(device)\n\n# 3. Load the saved weights\nmodel.load_state_dict(torch.load('model_without_attn.pt', map_location=device))\nmodel.eval()\n\n# 4. Define the loss criterion\ncriterion = torch.nn.CrossEntropyLoss(ignore_index=pad_idx)\n\ndv = TransliterationDataset('/kaggle/input/transliteration-9123/hi.translit.sampled.dev.tsv', src_vocab, tgt_vocab)\nval_dl = DataLoader(dv, batch_size=128, collate_fn=collate_fn)\n\n# 5. Run evaluation on the test set and save predictions\noutput_file = 'predictions_without_attention.txt'\ntest_loss, token_acc, char_acc, word_acc, _ = eval_epoch(\n    model, test_loader, criterion, beam_k=1, pad_idx=pad_idx, output_file=output_file\n)\n\nprint(f\"Test Loss: {test_loss:.4f}\")\nprint(f\"Test Token-level Accuracy: {token_acc:.4%}\")\nprint(f\"Character-level Accuracy: {char_acc:.2%}\")\nprint(f\"Word-level Accuracy: {word_acc:.2%}\")\nprint(f\"Predictions saved to: {output_file}\")\n","metadata":{"execution":{"iopub.status.busy":"2025-05-20T21:30:11.116138Z","iopub.execute_input":"2025-05-20T21:30:11.116698Z","iopub.status.idle":"2025-05-20T21:30:12.255737Z","shell.execute_reply.started":"2025-05-20T21:30:11.116673Z","shell.execute_reply":"2025-05-20T21:30:12.254954Z"},"papermill":{"duration":0.187928,"end_time":"2025-05-20T05:08:54.361201","exception":false,"start_time":"2025-05-20T05:08:54.173273","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stdout","text":"Saved 4502 predictions to predictions_without_attention.txt\nTest Loss: 5.2634\nTest Token-level Accuracy: 7.0872%\nCharacter-level Accuracy: 69.79%\nWord-level Accuracy: 36.96%\nPredictions saved to: predictions_without_attention.txt\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.169976,"end_time":"2025-05-20T05:08:54.707181","exception":false,"start_time":"2025-05-20T05:08:54.537205","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.173152,"end_time":"2025-05-20T05:08:55.051128","exception":false,"start_time":"2025-05-20T05:08:54.877976","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# CHECK","metadata":{"papermill":{"duration":0.173952,"end_time":"2025-05-20T05:08:55.476166","exception":false,"start_time":"2025-05-20T05:08:55.302214","status":"completed"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.170281,"end_time":"2025-05-20T05:08:55.819628","exception":false,"start_time":"2025-05-20T05:08:55.649347","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}